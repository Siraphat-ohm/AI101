{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xM3quqDoDJ-G",
        "sBPUIMlTNizL",
        "Fjw7cU-f-vBx",
        "NW5IAcgV-2Lz"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNYNdJVNOWA1EvTrFzJ/Sh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siraphat-ohm/AI101/blob/main/AI101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1 Introduction"
      ],
      "metadata": {
        "id": "xM3quqDoDJ-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get started"
      ],
      "metadata": {
        "id": "2Hf8G7htME2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print( tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTvdmGRQBVKf",
        "outputId": "2df65e8f-79fb-4fe2-af93-b278b779d870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI-zarWV_-WP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential( [ Dense( units=1, input_shape=[1] ) ] )\n",
        "model.compile( optimizer='sgd', loss='mean_squared_error' )"
      ],
      "metadata": {
        "id": "39J8z8GBBjR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array( [ -1.0, 0.0, 1.0, 2.0, 3.0, 4.0 ], dtype=float )\n",
        "ys = np.array( [ -3.0, -1.0, 1.0, 3.0, 5.0, 7.0 ], dtype=float )"
      ],
      "metadata": {
        "id": "XYSfiHXnB0kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( xs, ys, epochs=100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp7yhVuhCLz9",
        "outputId": "e85bdd4b-17da-4ab4-93fc-baf06fa21827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 1.7228\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4954\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3136\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1677\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0502\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9551\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8776\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8140\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7614\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7176\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6807\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6493\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6222\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5986\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5778\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5593\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5425\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5273\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5132\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5001\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4878\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4762\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4651\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4546\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4445\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4348\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4254\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4162\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4074\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3988\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3904\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3823\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3743\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3665\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3589\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3515\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3442\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.3371\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3302\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3234\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3167\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3102\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3038\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.2976\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2914\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2854\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2796\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2738\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2682\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2627\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2573\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2520\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2468\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2418\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2368\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2319\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2272\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2225\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2179\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2135\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2091\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2048\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2006\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1964\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1924\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1885\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1846\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1808\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1771\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1734\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1699\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1664\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1630\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1596\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1564\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1531\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1500\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1469\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1439\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1409\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1380\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1352\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1324\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1297\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1270\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1244\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1219\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1194\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1169\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1145\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1122\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1099\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1076\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1054\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1032\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1011\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0990\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0970\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0950\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0931\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7862e052a110>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bpLz8weNDkUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( model.predict( [ 10 ] ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U977PZpECQKp",
        "outputId": "ee9996c6-0d09-4162-afc1-f521c858b8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "[[18.109947]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing the Outcome: Understanding the Results of the Process"
      ],
      "metadata": {
        "id": "w06cGDD3MH1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l0 = Dense( units=1, input_shape=[1] )"
      ],
      "metadata": {
        "id": "f5LBnovXMaRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "05geG4LJDj9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential( [ l0 ] )\n",
        "model.compile( optimizer='sgd', loss='mean_squared_error' )"
      ],
      "metadata": {
        "id": "IlA-9y7ZMmDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( xs, ys, epochs=100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hi4mn6tMy0B",
        "outputId": "8813a64f-a2d6-4055-ad75-767d209adc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 3.0085\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5229\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1376\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8313\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5873\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3923\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2360\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1100\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0082\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9252\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8573\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8012\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7544\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7151\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6816\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6529\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6279\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6058\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5862\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5685\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5524\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5375\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5237\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5108\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4986\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4870\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4760\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4654\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4552\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4453\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4357\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4265\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4175\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4087\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4001\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3918\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3837\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3757\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3679\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3603\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3529\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3456\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3385\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3315\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3247\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3180\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3115\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3051\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2988\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2927\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2866\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2807\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2750\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2693\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2638\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2584\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2531\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2479\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2428\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2378\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2329\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2281\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2234\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2188\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2143\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2099\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2056\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2014\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1973\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1932\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1893\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1854\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1816\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1778\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1742\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1706\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1671\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1637\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1603\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1570\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1538\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1506\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1475\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1445\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1415\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1386\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1358\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1330\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1303\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1276\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1250\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1224\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1199\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1174\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1126\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1103\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1081\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1058\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7862e033dc60>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( model.predict( [ 10.0 ] ) )\n",
        "print( \"Here is what I learned: {}\".format(l0.get_weights()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ir4khlHM73_",
        "outputId": "03611a22-f9ec-4bcf-c76c-e5240f9f5bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "[[18.060574]]\n",
            "Here is what I learned: [array([[1.8638467]], dtype=float32), array([-0.57789314], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2 Introduction to computer vision"
      ],
      "metadata": {
        "id": "sBPUIMlTNizL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "NWZbnCbxNnnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.datasets.fashion_mnist\n",
        "( training_images, training_labels), ( test_images, test_labels ) = data.load_data()"
      ],
      "metadata": {
        "id": "lrfvswRxTI82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537058f9-d323-4576-b574-b0e8faf58e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "boAlzRFNTefg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential( [\n",
        "  tf.keras.layers.Flatten( input_shape=( 28, 28 ) ),\n",
        "  tf.keras.layers.Dense( 128, activation=tf.nn.relu ),\n",
        "  tf.keras.layers.Dense( 10, activation=tf.nn.softmax )\n",
        "] )\n",
        "\n",
        "model.compile( optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'] )"
      ],
      "metadata": {
        "id": "pzg1NyogTg9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( training_images, training_labels, epochs=5 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BpGIuB_Ukzm",
        "outputId": "ed601778-2cb0-447f-8595-a9a3ab7e57ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.5027 - accuracy: 0.8248\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3776 - accuracy: 0.8638\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3371 - accuracy: 0.8776\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3130 - accuracy: 0.8859\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2962 - accuracy: 0.8910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ab1d2316500>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate( test_images, test_labels )"
      ],
      "metadata": {
        "id": "EDWFk3KbVI65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d28717d-3636-4d15-bc97-c72613e2a892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3837 - accuracy: 0.8635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38367998600006104, 0.8634999990463257]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict( test_images )\n",
        "print( classifications[ 3 ] )\n",
        "print( test_labels[ 3 ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OXe6_N9gCeB",
        "outputId": "b0e20751-fa39-4164-e9da-3da1d5defee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "[7.14015130e-07 9.99896228e-01 3.50783864e-08 1.02775244e-04\n",
            " 1.57849200e-07 1.93027174e-11 2.83052284e-08 1.06960661e-14\n",
            " 2.33053177e-09 8.53069143e-11]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfit"
      ],
      "metadata": {
        "id": "VXiztg0Pgrx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( training_images, training_labels, epochs=50 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIDZk9JagRdR",
        "outputId": "105cd527-c2b3-4861-d3f9-84318e59660b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2805 - accuracy: 0.8956\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2696 - accuracy: 0.8996\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2602 - accuracy: 0.9030\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2483 - accuracy: 0.9088\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2419 - accuracy: 0.9090\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2328 - accuracy: 0.9128\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2253 - accuracy: 0.9163\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2176 - accuracy: 0.9186\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2116 - accuracy: 0.9206\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2050 - accuracy: 0.9231\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1982 - accuracy: 0.9259\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1932 - accuracy: 0.9283\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1875 - accuracy: 0.9295\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1837 - accuracy: 0.9309\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1795 - accuracy: 0.9324\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1739 - accuracy: 0.9339\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1702 - accuracy: 0.9356\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1656 - accuracy: 0.9386\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1623 - accuracy: 0.9392\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1581 - accuracy: 0.9416\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1546 - accuracy: 0.9419\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1510 - accuracy: 0.9432\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1474 - accuracy: 0.9447\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1437 - accuracy: 0.9475\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1416 - accuracy: 0.9467\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1404 - accuracy: 0.9473\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1373 - accuracy: 0.9484\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1333 - accuracy: 0.9499\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1306 - accuracy: 0.9503\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1267 - accuracy: 0.9535\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1260 - accuracy: 0.9517\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1220 - accuracy: 0.9545\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1188 - accuracy: 0.9554\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1163 - accuracy: 0.9560\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1151 - accuracy: 0.9564\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1139 - accuracy: 0.9565\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1122 - accuracy: 0.9582\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1078 - accuracy: 0.9595\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1089 - accuracy: 0.9586\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1067 - accuracy: 0.9603\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0999 - accuracy: 0.9624\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1025 - accuracy: 0.9628\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1017 - accuracy: 0.9619\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0990 - accuracy: 0.9626\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0965 - accuracy: 0.9642\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0960 - accuracy: 0.9644\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0931 - accuracy: 0.9646\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0930 - accuracy: 0.9660\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0919 - accuracy: 0.9653\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0919 - accuracy: 0.9656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ab1c376e530>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate( test_images, test_labels )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB3ryU_fhFGO",
        "outputId": "945f3deb-8794-4bee-ed3d-8ae727e342c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5267 - accuracy: 0.8893\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5267238616943359, 0.8892999887466431]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback"
      ],
      "metadata": {
        "id": "H6okb2d2ZRUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "z181CkkrZUAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback( tf.keras.callbacks.Callback ):\n",
        "  def on_epoch_end( self, epoch, logs={ } ):\n",
        "    if ( logs.get('accuracy') > 0.95 ):\n",
        "      print( \"\\n Reached 95% accuracy so cancelling training!\" )\n",
        "      self.mode.stop_training = True"
      ],
      "metadata": {
        "id": "z00GOLA0ZWNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "( training_images, training_labels), ( test_images, test_labels ) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djjjh6l4ZyVY",
        "outputId": "73f2e939-712b-4c1e-c0a7-7349f7395834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traing_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "ybOISMKPZ-8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential( [\n",
        "    tf.keras.layers.Flatten(  ),\n",
        "    tf.keras.layers.Dense( 128, activation=tf.nn.relu ),\n",
        "    tf.keras.layers.Dense( 10, activation=tf.nn.softmax )\n",
        "] )"
      ],
      "metadata": {
        "id": "1DAieoPAaKJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] )"
      ],
      "metadata": {
        "id": "BPW4tygGagiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( training_images, training_labels, epochs=50, callbacks=[callbacks] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysk9uuy6a1qz",
        "outputId": "43af60e3-cfe0-4efa-b34d-ca471304a0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 3.2621 - accuracy: 0.7141\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6390 - accuracy: 0.7715\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5837 - accuracy: 0.7916\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5585 - accuracy: 0.8040\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5441 - accuracy: 0.8091\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5299 - accuracy: 0.8173\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5074 - accuracy: 0.8254\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5102 - accuracy: 0.8256\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4976 - accuracy: 0.8282\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4961 - accuracy: 0.8300\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4922 - accuracy: 0.8322\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4852 - accuracy: 0.8348\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4878 - accuracy: 0.8349\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4793 - accuracy: 0.8385\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4755 - accuracy: 0.8405\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4665 - accuracy: 0.8409\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4791 - accuracy: 0.8395\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4718 - accuracy: 0.8431\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4679 - accuracy: 0.8430\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4702 - accuracy: 0.8468\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4599 - accuracy: 0.8450\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4631 - accuracy: 0.8456\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4624 - accuracy: 0.8465\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4546 - accuracy: 0.8484\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4553 - accuracy: 0.8495\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4555 - accuracy: 0.8473\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4615 - accuracy: 0.8491\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4570 - accuracy: 0.8479\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4508 - accuracy: 0.8499\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4470 - accuracy: 0.8530\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4500 - accuracy: 0.8503\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4532 - accuracy: 0.8509\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4471 - accuracy: 0.8530\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4541 - accuracy: 0.8516\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4408 - accuracy: 0.8544\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4485 - accuracy: 0.8520\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4414 - accuracy: 0.8546\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4421 - accuracy: 0.8537\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4508 - accuracy: 0.8513\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4436 - accuracy: 0.8562\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4316 - accuracy: 0.8569\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4408 - accuracy: 0.8551\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4468 - accuracy: 0.8536\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4466 - accuracy: 0.8556\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4362 - accuracy: 0.8565\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4352 - accuracy: 0.8575\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4429 - accuracy: 0.8552\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4272 - accuracy: 0.8579\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4547 - accuracy: 0.8519\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4271 - accuracy: 0.8600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b370eb0d540>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iVCs4T0wbHAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3 : CNN"
      ],
      "metadata": {
        "id": "dUxG_940Cvxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST"
      ],
      "metadata": {
        "id": "Fjw7cU-f-vBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0puokO4pC0G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "BLHef-QOC-bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "( training_images, training_labels ), ( test_images, test_labels ) = data.load_data()"
      ],
      "metadata": {
        "id": "mDTPOY0xDDfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images.reshape( 60000, 28, 28, 1 )\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images.reshape( 10000, 28, 28, 1 )\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "03COxZiCIxl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential( [\n",
        "    tf.keras.layers.Conv2D( 10, ( 3, 3 ), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D( 64, ( 3, 3 ), activation=\"relu\" ),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense( 128, activation=tf.nn.relu ),\n",
        "    tf.keras.layers.Dense( 10, activation=tf.nn.softmax )\n",
        "] )"
      ],
      "metadata": {
        "id": "kFhF8aNTDPM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] )"
      ],
      "metadata": {
        "id": "hIZq0bBODvtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( training_images, training_labels, epochs=10 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYWEKT4hKxCF",
        "outputId": "c164ca38-ea68-412f-cdd1-f0995f973f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 33s 17ms/step - loss: 0.4547 - accuracy: 0.8344\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.3202 - accuracy: 0.8820\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.2714 - accuracy: 0.8991\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.2394 - accuracy: 0.9110\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2163 - accuracy: 0.9190\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.1928 - accuracy: 0.9273\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.1718 - accuracy: 0.9353\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.1544 - accuracy: 0.9414\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.1376 - accuracy: 0.9479\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.1240 - accuracy: 0.9533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7862cdddf8b0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate( test_images, test_labels )"
      ],
      "metadata": {
        "id": "HisFaVnpLNNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3308c1-f4d9-42a1-ea15-e6a71a781dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 11ms/step - loss: 0.6720 - accuracy: 0.9115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.671955406665802, 0.9114999771118164]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict( test_images )\n",
        "print( classifications[0])\n",
        "print( test_labels[0] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFnkua3fssTr",
        "outputId": "477eacfe-1b67-4eeb-ca87-a0fffcb240e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 11ms/step\n",
            "[2.0980857e-27 2.0210861e-17 2.3698500e-16 4.2214819e-21 2.3804103e-27\n",
            " 4.9378517e-17 1.6194844e-25 2.5332410e-17 3.7817664e-25 9.9999994e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHXiM07rs75s",
        "outputId": "b7f7d14e-1dd1-42e7-b8c0-015cceeedac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 10)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 64)        5824      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212142 (828.68 KB)\n",
            "Trainable params: 212142 (828.68 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0jigg_16-0dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Humans vs Horses"
      ],
      "metadata": {
        "id": "NW5IAcgV-2Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "DCJHEWTU-7RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n",
        "\n",
        "file_name = \"horse-or-human.zip\"\n",
        "training_dir = \"horse-or-human/training/\"\n",
        "urllib.request.urlretrieve( url, file_name )\n",
        "\n",
        "zip_ref = zipfile.ZipFile( file_name, 'r' )\n",
        "zip_ref.extractall( training_dir )\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "PT4ts5rufXI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
        "validation_file_name = \"validation-horse-or-human.zip\"\n",
        "validation_dir = 'horse-or-human/validation/'\n",
        "urllib.request.urlretrieve(validation_url, validation_file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "LuSnUno6BK4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "xKZjTy1g_jEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator( rescale = 1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size=( 300, 300 ),\n",
        "    class_mode=\"binary\",\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTbCprz7At-5",
        "outputId": "4f5bcf38-c4f8-4c20-cef9-71048fb5d3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(300, 300),\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGH5D3LIBAYx",
        "outputId": "60ebc151-e338-43d4-da01-d60d6220e2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Mgv-4XdlBYME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential( [\n",
        "    tf.keras.layers.Conv2D( 16, ( 3, 3 ), activation='relu', input_shape=( 300, 300, 3 ) ),\n",
        "    tf.keras.layers.MaxPooling2D( 2, 2 ),\n",
        "    tf.keras.layers.Conv2D( 32, ( 3, 3 ), activation='relu' ),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D( 64, ( 3, 3 ), activation='relu' ),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D( 64, ( 3, 3 ), activation='relu' ),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D( 64, ( 3, 3 ), activation='relu' ),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense( 512, activation='relu' ),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid' )\n",
        "])"
      ],
      "metadata": {
        "id": "53gr1NozWVsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GuIdBvHXnmJ",
        "outputId": "e5d5229e-dc28-48eb-d4e7-db7d9026e536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 298, 298, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 149, 149, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 147, 147, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 73, 73, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 35, 35, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 33, 33, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1704097 (6.50 MB)\n",
            "Trainable params: 1704097 (6.50 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "Bu3hjZ_7MmL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( loss=\"binary_crossentropy\", optimizer=RMSprop( lr=0.001 ), metrics=['accuracy'] )"
      ],
      "metadata": {
        "id": "luRZu7gNXzf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c03632-2f1a-4bf3-8d89-351f0e169b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator( train_generator, epochs=20, validation_data=validation_generator )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2tG-lUqMYpV",
        "outputId": "7875317b-27f8-44ef-8a8a-9d98ba2a58ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-786f6021a1d4>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator( train_generator, epochs=20, validation_data=validation_generator )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "33/33 [==============================] - 140s 4s/step - loss: 0.6985 - accuracy: 0.5540 - val_loss: 0.7611 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "33/33 [==============================] - 145s 4s/step - loss: 0.6524 - accuracy: 0.6475 - val_loss: 0.8239 - val_accuracy: 0.5039\n",
            "Epoch 3/20\n",
            "33/33 [==============================] - 143s 4s/step - loss: 0.5368 - accuracy: 0.7186 - val_loss: 0.9139 - val_accuracy: 0.5586\n",
            "Epoch 4/20\n",
            "33/33 [==============================] - 138s 4s/step - loss: 0.4723 - accuracy: 0.7712 - val_loss: 3.0491 - val_accuracy: 0.5234\n",
            "Epoch 5/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.4629 - accuracy: 0.7975 - val_loss: 1.2490 - val_accuracy: 0.6055\n",
            "Epoch 6/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.3580 - accuracy: 0.8423 - val_loss: 0.7240 - val_accuracy: 0.6445\n",
            "Epoch 7/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.3394 - accuracy: 0.8598 - val_loss: 1.0440 - val_accuracy: 0.6562\n",
            "Epoch 8/20\n",
            "33/33 [==============================] - 142s 4s/step - loss: 0.2727 - accuracy: 0.8870 - val_loss: 2.0075 - val_accuracy: 0.6172\n",
            "Epoch 9/20\n",
            "33/33 [==============================] - 143s 4s/step - loss: 0.3158 - accuracy: 0.9026 - val_loss: 0.9498 - val_accuracy: 0.6836\n",
            "Epoch 10/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.1817 - accuracy: 0.9357 - val_loss: 2.3299 - val_accuracy: 0.6094\n",
            "Epoch 11/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.2604 - accuracy: 0.9172 - val_loss: 2.4976 - val_accuracy: 0.5938\n",
            "Epoch 12/20\n",
            "33/33 [==============================] - 143s 4s/step - loss: 0.1509 - accuracy: 0.9503 - val_loss: 2.6796 - val_accuracy: 0.5938\n",
            "Epoch 13/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.1841 - accuracy: 0.9377 - val_loss: 2.6962 - val_accuracy: 0.5547\n",
            "Epoch 14/20\n",
            "33/33 [==============================] - 142s 4s/step - loss: 0.1366 - accuracy: 0.9494 - val_loss: 2.0827 - val_accuracy: 0.6602\n",
            "Epoch 15/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.1193 - accuracy: 0.9620 - val_loss: 2.6152 - val_accuracy: 0.6367\n",
            "Epoch 16/20\n",
            "33/33 [==============================] - 140s 4s/step - loss: 0.1310 - accuracy: 0.9581 - val_loss: 1.2027 - val_accuracy: 0.7031\n",
            "Epoch 17/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.1499 - accuracy: 0.9464 - val_loss: 1.1922 - val_accuracy: 0.6992\n",
            "Epoch 18/20\n",
            "33/33 [==============================] - 141s 4s/step - loss: 0.1036 - accuracy: 0.9708 - val_loss: 0.9029 - val_accuracy: 0.7461\n",
            "Epoch 19/20\n",
            "33/33 [==============================] - 142s 4s/step - loss: 0.0868 - accuracy: 0.9640 - val_loss: 1.9506 - val_accuracy: 0.5898\n",
            "Epoch 20/20\n",
            "33/33 [==============================] - 144s 4s/step - loss: 0.1579 - accuracy: 0.9552 - val_loss: 0.2291 - val_accuracy: 0.9219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "Pge0J6w_M4TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img( path, target_size=( 300, 300 ) )\n",
        "  x = image.img_to_array( img )\n",
        "  x = np.expand_dims( x, axis=0 )\n",
        "\n",
        "  image_tensor = np.vstack( [x] )\n",
        "  classes = model.predict( image_tensor )\n",
        "  print( classes )\n",
        "  print( classes[0] )\n",
        "  if ( classes[0] > 0.5 ): print( fn + \" is a human\" )\n",
        "  else: print( fn + \" is a horse\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "9zji3JZnXtlv",
        "outputId": "4fa9acf9-eae9-4f1e-8274-418da7e9526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6a344f8-d3fa-4144-b072-ad005e73cc88\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6a344f8-d3fa-4144-b072-ad005e73cc88\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20220707_113811.jpg to 20220707_113811 (1).jpg\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "[[0.]]\n",
            "[0.]\n",
            "20220707_113811 (1).jpg is a horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning"
      ],
      "metadata": {
        "id": "vuSCaAh2eWct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "XkJekJLwYgVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request"
      ],
      "metadata": {
        "id": "avF4mc1vfNSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "weights_file = \"inception_v3.h5\""
      ],
      "metadata": {
        "id": "6_j4BT9Kepzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve( weights_url, weights_file )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyEu53eOfdar",
        "outputId": "85ca06d2-e7c5-4f0f-f95b-c6a7c2c88085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('inception_v3.h5', <http.client.HTTPMessage at 0x7fab1ba20c10>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = InceptionV3( input_shape=( 150, 150, 3 ), include_top=False, weights=None )\n",
        "pre_trained_model.load_weights( weights_file )"
      ],
      "metadata": {
        "id": "91r2ffMofpxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbaDDgPRgT5Q",
        "outputId": "094928e7-a3d3-42a6-c467-d16f56b68428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 74, 74, 32)           864       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 74, 74, 32)           96        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 74, 74, 32)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)           9216      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 72, 72, 32)           96        ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 72, 72, 32)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 72, 72, 64)           18432     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 72, 72, 64)           192       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 72, 72, 64)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 35, 35, 64)           0         ['activation_2[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 35, 35, 80)           5120      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 35, 35, 80)           240       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 35, 35, 80)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 33, 33, 192)          138240    ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 33, 33, 192)          576       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 33, 33, 192)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_4[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 64)           192       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 48)           9216      ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 96)           55296     ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 48)           144       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 96)           288       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 16, 16, 48)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 16, 16, 96)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 16, 16, 192)          0         ['max_pooling2d_1[0][0]']     \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 64)           76800     ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 32)           6144      ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 16, 16, 64)           192       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 64)           192       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 96)           288       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 16, 16, 32)           96        ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_5[0][0]',        \n",
            "                                                                     'activation_7[0][0]',        \n",
            "                                                                     'activation_10[0][0]',       \n",
            "                                                                     'activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 16, 16, 64)           192       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 16, 16, 48)           144       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 16, 16, 96)           288       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 64)           16384     ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 64)           192       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 64)           192       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 16, 16, 96)           288       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 16, 16, 64)           192       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_12[0][0]',       \n",
            "                                                                     'activation_14[0][0]',       \n",
            "                                                                     'activation_17[0][0]',       \n",
            "                                                                     'activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 16, 16, 64)           192       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 16, 16, 48)           144       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 16, 16, 96)           288       ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (Avera  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 16, 16, 64)           18432     ['average_pooling2d_2[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 16, 16, 64)           192       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 16, 16, 64)           192       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 16, 16, 96)           288       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 16, 16, 64)           192       ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_19[0][0]',       \n",
            "                                                                     'activation_21[0][0]',       \n",
            "                                                                     'activation_24[0][0]',       \n",
            "                                                                     'activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 16, 16, 64)           192       ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 16, 16, 96)           288       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 7, 7, 96)             82944     ['activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 7, 7, 384)            1152      ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 7, 7, 96)             288       ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 7, 7, 384)            0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 7, 7, 96)             0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_26[0][0]',       \n",
            "                                                                     'activation_29[0][0]',       \n",
            "                                                                     'max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 7, 7, 128)            384       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 7, 7, 128)            384       ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 7, 7, 128)            384       ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 7, 7, 128)            384       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_31[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 7, 7, 128)            384       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 7, 7, 128)            384       ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (Avera  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_3[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 7, 7, 192)            576       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 7, 7, 192)            576       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 7, 7, 192)            576       ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 7, 7, 192)            576       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_30[0][0]',       \n",
            "                                                                     'activation_33[0][0]',       \n",
            "                                                                     'activation_38[0][0]',       \n",
            "                                                                     'activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 7, 7, 160)            480       ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 7, 7, 160)            480       ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 7, 7, 160)            480       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 7, 7, 160)            480       ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 7, 7, 160)            480       ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 7, 7, 160)            480       ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (Avera  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_47[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_4[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 7, 7, 192)            576       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 7, 7, 192)            576       ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 7, 7, 192)            576       ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 7, 7, 192)            576       ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_40[0][0]',       \n",
            "                                                                     'activation_43[0][0]',       \n",
            "                                                                     'activation_48[0][0]',       \n",
            "                                                                     'activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 7, 7, 160)            480       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_54[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 7, 7, 160)            480       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 7, 7, 160)            480       ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 7, 7, 160)            480       ['conv2d_56[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 7, 7, 160)            480       ['conv2d_52[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 7, 7, 160)            480       ['conv2d_57[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (Avera  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_57[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_5[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 7, 7, 192)            576       ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 7, 7, 192)            576       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 7, 7, 192)            576       ['conv2d_58[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 7, 7, 192)            576       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_50[0][0]',       \n",
            "                                                                     'activation_53[0][0]',       \n",
            "                                                                     'activation_58[0][0]',       \n",
            "                                                                     'activation_59[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 7, 7, 192)            576       ['conv2d_64[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 7, 7, 192)            576       ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 7, 7, 192)            576       ['conv2d_61[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 7, 7, 192)            576       ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 7, 7, 192)            576       ['conv2d_62[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 7, 7, 192)            576       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (Avera  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_67[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_6[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 7, 7, 192)            576       ['conv2d_60[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 7, 7, 192)            576       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 7, 7, 192)            576       ['conv2d_68[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 7, 7, 192)            576       ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_60[0][0]',       \n",
            "                                                                     'activation_63[0][0]',       \n",
            "                                                                     'activation_68[0][0]',       \n",
            "                                                                     'activation_69[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 7, 7, 192)            576       ['conv2d_72[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_72[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 7, 7, 192)            576       ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 7, 7, 192)            576       ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 7, 7, 192)            576       ['conv2d_74[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 3, 3, 320)            552960    ['activation_70[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 3, 3, 192)            331776    ['activation_74[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 3, 3, 320)            960       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 3, 3, 192)            576       ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 3, 3, 192)            0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_71[0][0]',       \n",
            "                                                                     'activation_75[0][0]',       \n",
            "                                                                     'max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 3, 3, 448)            1344      ['conv2d_80[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_80 (Activation)  (None, 3, 3, 448)            0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 3, 3, 384)            1548288   ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 3, 3, 384)            1152      ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 3, 3, 384)            1152      ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_77 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_81 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_81[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_81[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (Avera  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 3, 3, 384)            1152      ['conv2d_78[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 3, 3, 384)            1152      ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 3, 3, 384)            1152      ['conv2d_82[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_83 (Ba  (None, 3, 3, 384)            1152      ['conv2d_83[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 3, 3, 192)            245760    ['average_pooling2d_7[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 3, 3, 320)            960       ['conv2d_76[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_78 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_79 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_82 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_83 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_83[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (Ba  (None, 3, 3, 192)            576       ['conv2d_84[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_76 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_78[0][0]',       \n",
            "                                                                     'activation_79[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 3, 3, 768)            0         ['activation_82[0][0]',       \n",
            "                                                                     'activation_83[0][0]']       \n",
            "                                                                                                  \n",
            " activation_84 (Activation)  (None, 3, 3, 192)            0         ['batch_normalization_84[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_76[0][0]',       \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate[0][0]',         \n",
            "                                                                     'activation_84[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_89 (Ba  (None, 3, 3, 448)            1344      ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_89 (Activation)  (None, 3, 3, 448)            0         ['batch_normalization_89[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 3, 3, 384)            1548288   ['activation_89[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_86 (Ba  (None, 3, 3, 384)            1152      ['conv2d_86[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_90 (Ba  (None, 3, 3, 384)            1152      ['conv2d_90[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_86 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_86[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_90 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_90[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (Avera  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_87 (Ba  (None, 3, 3, 384)            1152      ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_88 (Ba  (None, 3, 3, 384)            1152      ['conv2d_88[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_91 (Ba  (None, 3, 3, 384)            1152      ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_92 (Ba  (None, 3, 3, 384)            1152      ['conv2d_92[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 3, 3, 192)            393216    ['average_pooling2d_8[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_85 (Ba  (None, 3, 3, 320)            960       ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_87 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_87[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_88 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_88[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_91 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_91[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_92 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_92[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (Ba  (None, 3, 3, 192)            576       ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_85 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_85[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_87[0][0]',       \n",
            "                                                                     'activation_88[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 3, 3, 768)            0         ['activation_91[0][0]',       \n",
            " )                                                                   'activation_92[0][0]']       \n",
            "                                                                                                  \n",
            " activation_93 (Activation)  (None, 3, 3, 192)            0         ['batch_normalization_93[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_85[0][0]',       \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_1[0][0]',       \n",
            "                                                                     'activation_93[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21802784 (83.17 MB)\n",
            "Trainable params: 21768352 (83.04 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = pre_trained_model.get_layer( \"mixed7\" )\n",
        "print( 'last layer output shape: ', last_layer.output_shape )\n",
        "last_output = last_layer.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn7dC7Z6gc4E",
        "outputId": "d924c18f-7932-4e88-fb22-401ab65fbf09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Flatten()( last_output )\n",
        "x = layers.Dense( 128, activation = 'relu' )( x )\n",
        "x = layers.Dense( 1, activation = 'sigmoid' )( x )"
      ],
      "metadata": {
        "id": "uodjha5DiAL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model( pre_trained_model.input, x )"
      ],
      "metadata": {
        "id": "B-gQHuPdiCQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( optimizer=RMSprop( lr = 0.0001 ),\n",
        "              loss='binary_crossentropy',\n",
        "               metrics=['acc']\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv_NUkyyin20",
        "outputId": "c81c00c2-0d51-4729-e06c-fb76a2db592a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile"
      ],
      "metadata": {
        "id": "hiTaSU5ei2zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n",
        "training_file_name = \"horse-or-human.zip\"\n",
        "training_dir = 'horse-or-human/training/'\n",
        "urllib.request.urlretrieve(training_url, training_file_name)\n",
        "zip_ref = zipfile.ZipFile(training_file_name, 'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()\n",
        "\n",
        "validation_url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
        "validation_file_name = \"validation-horse-or-human.zip\"\n",
        "validation_dir = 'horse-or-human/validation/'\n",
        "urllib.request.urlretrieve(validation_url, validation_file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "2Ii7c5rujhen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(training_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode='binary',\n",
        "                                                         target_size=(150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1qEvYoDjmrW",
        "outputId": "b142bada-5a45-456d-dc8a-8c2eddf26963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=20,\n",
        "            verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX5vHrXejvVf",
        "outputId": "4126ae9f-e384-46dc-b6d7-65f2ba39187c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-bd01b38aed94>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "52/52 [==============================] - 22s 274ms/step - loss: 0.4397 - acc: 0.9338 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 2/20\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0662 - acc: 0.9776 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 3/20\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0270 - acc: 0.9912 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 4/20\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0356 - acc: 0.9932 - val_loss: 0.0250 - val_acc: 0.9922\n",
            "Epoch 5/20\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0215 - acc: 0.9942 - val_loss: 0.0750 - val_acc: 0.9844\n",
            "Epoch 6/20\n",
            "52/52 [==============================] - 13s 255ms/step - loss: 0.0396 - acc: 0.9883 - val_loss: 9.0763e-04 - val_acc: 1.0000\n",
            "Epoch 7/20\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0154 - acc: 0.9942 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 8/20\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0153 - acc: 0.9961 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 9/20\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0162 - acc: 0.9961 - val_loss: 3.7933e-04 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0042 - acc: 0.9981 - val_loss: 0.0137 - val_acc: 0.9922\n",
            "Epoch 11/20\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0016 - acc: 0.9990 - val_loss: 0.0165 - val_acc: 0.9922\n",
            "Epoch 12/20\n",
            "52/52 [==============================] - 12s 226ms/step - loss: 0.0114 - acc: 0.9942 - val_loss: 0.0036 - val_acc: 0.9961\n",
            "Epoch 13/20\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 0.0021 - acc: 0.9990 - val_loss: 0.0126 - val_acc: 0.9922\n",
            "Epoch 14/20\n",
            "52/52 [==============================] - 12s 221ms/step - loss: 0.0197 - acc: 0.9942 - val_loss: 0.0529 - val_acc: 0.9922\n",
            "Epoch 15/20\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0320 - acc: 0.9932 - val_loss: 0.0195 - val_acc: 0.9961\n",
            "Epoch 16/20\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0115 - acc: 0.9961 - val_loss: 0.0023 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0083 - acc: 0.9951 - val_loss: 2.2082e-05 - val_acc: 1.0000\n",
            "Epoch 18/20\n",
            "52/52 [==============================] - 12s 227ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 1.2406e-06 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "52/52 [==============================] - 12s 225ms/step - loss: 0.0150 - acc: 0.9951 - val_loss: 0.0041 - val_acc: 0.9961\n",
            "Epoch 20/20\n",
            "52/52 [==============================] - 12s 228ms/step - loss: 1.1498e-04 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "BgUd85yPlqBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img( path, target_size=( 150, 150 ) )\n",
        "  x = image.img_to_array( img )\n",
        "  x = np.expand_dims( x , axis=0 )\n",
        "\n",
        "  image_tensor = np.vstack([x])\n",
        "  classes = model.predict( image_tensor )\n",
        "  print( classes )\n",
        "  print( classes[0] )\n",
        "  if ( classes[0] > 0.5 ): print( fn + \" is a human.\")\n",
        "  else : print( fn + \" is a horse.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "U3VSi_XelyIw",
        "outputId": "46e7a2d1-4498-468c-dce3-9a05f0bf1e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6112a67-c316-4620-a57d-de64600e316a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6112a67-c316-4620-a57d-de64600e316a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20220707_113811.jpg to 20220707_113811.jpg\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "[[1.]]\n",
            "[1.]\n",
            "20220707_113811.jpg is a human.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fgl5kh0FmXpm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}